{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 1\n",
    "\n",
    "Реализуйте стохастический градиентный спуск для решения линейной регрессии. Исследуйте сходимость с разным размером батча (1 - SGD, 2, $\\ldots$, $n - 1$ - Minibatch GD, $n$ - GD из предыдущей работы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..' + '/')\n",
    "\n",
    "from helper import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class get_model_LinearRegression:\n",
    "    def __init__(self, batch_size=None):\n",
    "        self.coef_ = []\n",
    "        self.intercept_ = None\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def fit(self, X_train, y_train, epsilon=1e-5, learning_rate=0.01, max_epochs=1000, batch_size=1, apply_min=False):\n",
    "        X = X_train \n",
    "        y = y_train\n",
    "\n",
    "        if self.batch_size is not None:\n",
    "            batch_size = self.batch_size\n",
    "\n",
    "        def mse_loss(w):\n",
    "            y_pred = np.dot(X, w)\n",
    "            mse = np.mean((y_pred - y)**2)\n",
    "            return mse\n",
    "\n",
    "        x0 = np.zeros(X.shape[1], dtype=float)\n",
    "\n",
    "        point, _, _ = stochastic_gradient_descent(mse_loss, x0, epsilon=epsilon, learning_rate=learning_rate, max_epochs=max_epochs, batch_size=batch_size, apply_min=apply_min)\n",
    "\n",
    "        self.coef_ = point[:-1]\n",
    "        self.intercept_ = point[-1] \n",
    "\n",
    "    def predict(self, X_test):\n",
    "        y_pred = []\n",
    "\n",
    "        for i in range(len(X_test)):\n",
    "            y = self.intercept_ + sum([self.coef_[j] * float(X_test[i][j]) for j in range(len(self.coef_))])\n",
    "            y_pred.append(y)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "boston = fetch_openml(name='boston', version=1, as_frame=True , parser='liac-arff')\n",
    "\n",
    "\n",
    "results = []\n",
    "\n",
    "for i in range(1, boston.data.values.shape[1] + 1):\n",
    "    model = get_model_LinearRegression(batch_size=i)\n",
    "    results.append(train_test_print_model(model, boston, print_result=False, view_graphics=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(45.32101453393082, 0.3819899563227275), (84.79164837326567, -0.1562426581469749), (89.78954710098428, -0.2243954045666181), (63.036807232677894, 0.1404124468136838), (179.03025399211015, -1.4413066703610893), (52.873964070031505, 0.27899582168783), (170.12961671358372, -1.3199350883295473), (116.39504659179306, -0.587195444933329), (60.85565188927208, 0.17015529178102096), (122.78052186825185, -0.6742695736810413), (1136.5844597812195, -14.498783927407764), (535.0780392156863, -6.296473959974136), (254.72073031516558, -2.473443198181838)]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
